# ğŸš€ DynamicKV: Task-Aware Adaptive KV Cache Compression for Long-Context LLMs  
# ğŸš€ DynamicKVï¼šé¢å‘ä»»åŠ¡è‡ªé€‚åº”çš„é•¿ä¸Šä¸‹æ–‡å¤§æ¨¡å‹ KV ç¼“å­˜å‹ç¼©æ–¹æ³•

<div align="center">

<!-- Language Toggle -->
<button onclick="toggleLang('en')" style="margin:5px;">English</button>
<button onclick="toggleLang('zh')" style="margin:5px;">ä¸­æ–‡</button>

<script>
function toggleLang(lang) {
  const enElems = document.querySelectorAll('.lang-en');
  const zhElems = document.querySelectorAll('.lang-zh');
  if (lang === 'en') {
    enElems.forEach(el => el.style.display = 'block');
    zhElems.forEach(el => el.style.display = 'none');
  } else {
    enElems.forEach(el => el.style.display = 'none');
    zhElems.forEach(el => el.style.display = 'block');
  }
}
// Default: show English
document.addEventListener('DOMContentLoaded', () => {
  toggleLang('en');
});
</script>

</div>

---

<div class="lang-en">

[![Paper](https://img.shields.io/badge/arXiv-2412.14838-b31b1b.svg)](https://arxiv.org/abs/2412.14838)  
[![License](https://img.shields.io/badge/license-MIT-green)](LICENSE)  
[![Python 3.9+](https://img.shields.io/badge/python-3.9%2B-blue)]()

**DynamicKV** is a task-aware, layer-adaptive KV cache compression method for long-context LLM inference. It dynamically allocates KV cache budgets per layer based on task-specific attention patterns, achieving **~90% of FullKV performance with only 1.7% cache retention**.

> ğŸ’¡ **Key Insight**: Different tasks (e.g., QA, summarization, code completion) exhibit distinct token importance distributions across transformer layers. Fixed-pattern compression (e.g., pyramid, sliding window) fails to capture this variability.

</div>

<div class="lang-zh" style="display:none">

[![è®ºæ–‡](https://img.shields.io/badge/arXiv-2412.14838-b31b1b.svg)](https://arxiv.org/abs/2412.14838)  
[![è®¸å¯è¯](https://img.shields.io/badge/è®¸å¯è¯-MIT-green)](LICENSE)  
[![Python 3.9+](https://img.shields.io/badge/python-3.9%2B-blue)]()

**DynamicKV** æ˜¯ä¸€ç§é¢å‘ä»»åŠ¡è‡ªé€‚åº”çš„é•¿ä¸Šä¸‹æ–‡å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰KV ç¼“å­˜å‹ç¼©æ–¹æ³•ã€‚å®ƒæ ¹æ®ä»»åŠ¡ç‰¹æœ‰çš„æ³¨æ„åŠ›åˆ†å¸ƒï¼ŒåŠ¨æ€ä¸ºæ¯ä¸€å±‚åˆ†é…ç¼“å­˜é¢„ç®—ï¼Œåœ¨ä»…ä¿ç•™ **1.7% KV ç¼“å­˜** çš„æƒ…å†µä¸‹ä»èƒ½è¾¾åˆ° **çº¦ 90% çš„åŸå§‹æ€§èƒ½**ã€‚

> ğŸ’¡ **æ ¸å¿ƒæ´å¯Ÿ**ï¼šä¸åŒä»»åŠ¡ï¼ˆå¦‚é—®ç­”ã€æ‘˜è¦ã€ä»£ç è¡¥å…¨ï¼‰åœ¨ Transformer å„å±‚å¯¹ token çš„é‡è¦æ€§åˆ†å¸ƒæ˜¾è‘—ä¸åŒã€‚å›ºå®šæ¨¡å¼å‹ç¼©æ–¹æ³•ï¼ˆå¦‚é‡‘å­—å¡”ç»“æ„ã€æ»‘åŠ¨çª—å£ï¼‰æ— æ³•é€‚é…è¿™ç§å·®å¼‚ã€‚

</div>

---

## ğŸ” Method Overview / æ–¹æ³•ç®€ä»‹

<div class="lang-en">

### Why DynamicKV?
Existing KV compression methods (e.g., StreamingLLM, PyramidKV) use **fixed retention patterns** across layers and tasks, ignoring task-specific attention dynamics.

### How It Works
1. **Dynamic Budget Allocation**: For each layer, retain top-K tokens based on attention scores with the most recent window.
2. **Progressive Cache Update**: Every `m` layers, globally re-normalize and adjust historical KV cache sizes to respect total memory budget.

### Advantages
- âœ… **Task-aware**: Adapts to QA, summarization, code, etc.
- âœ… **High compression**: 1.7% cache â†’ 90% performance.
- âœ… **No training required**.
- âŒ›ï¸ **Plug-and-play**: Only modifies prefill phase; compatible with vLLM, FlashAttention.

</div>

<div class="lang-zh" style="display:none">

### ä¸ºä»€ä¹ˆéœ€è¦ DynamicKVï¼Ÿ
ç°æœ‰ KV å‹ç¼©æ–¹æ³•ï¼ˆå¦‚ StreamingLLMã€PyramidKVï¼‰åœ¨æ‰€æœ‰ä»»åŠ¡å’Œå±‚ä¸Šä½¿ç”¨**å›ºå®šä¿ç•™æ¨¡å¼**ï¼Œå¿½ç•¥äº†ä»»åŠ¡ç‰¹æœ‰çš„æ³¨æ„åŠ›åŠ¨æ€ã€‚

### å·¥ä½œåŸç†
1. **åŠ¨æ€é¢„ç®—åˆ†é…**ï¼šæ¯å±‚æ ¹æ®ä¸æœ€è¿‘çª—å£ token çš„æ³¨æ„åŠ›å¾—åˆ†ï¼Œä¿ç•™ top-K é‡è¦ tokenã€‚
2. **æ¸è¿›å¼ç¼“å­˜æ›´æ–°**ï¼šæ¯ `m` å±‚ï¼Œå…¨å±€é‡æ–°å½’ä¸€åŒ–å¹¶è°ƒæ•´å†å²å±‚çš„ KV ç¼“å­˜å¤§å°ï¼Œç¡®ä¿æ€»å†…å­˜é¢„ç®—ä¸è¶…é™ã€‚

### ä¼˜åŠ¿
- âœ… **ä»»åŠ¡æ„ŸçŸ¥**ï¼šè‡ªåŠ¨é€‚é…é—®ç­”ã€æ‘˜è¦ã€ä»£ç ç­‰ä»»åŠ¡ã€‚
- âœ… **é«˜å‹ç¼©ç‡**ï¼šä»… 1.7% ç¼“å­˜å³å¯ä¿ç•™ 90% æ€§èƒ½ã€‚
- âœ… **æ— éœ€è®­ç»ƒ**ã€‚
- âŒ›ï¸ **å³æ’å³ç”¨**ï¼šä»…ä¿®æ”¹ prefill é˜¶æ®µï¼Œå…¼å®¹ vLLMã€FlashAttentionã€‚

</div>

---

## ğŸ“Š Model Comparison / æ¨¡å‹å¯¹æ¯”ï¼ˆLongBench, KV Cache = 512ï¼‰

<div class="lang-en">

| Model | FullKV | StreamingLLM | H2O | SnapKV | PyramidKV | **DynamicKV (Ours)** |
|-------|--------|--------------|-----|--------|-----------|----------------------|
| Llama-3-8B-Instruct | 41.95 | 34.70 | 37.20 | 40.30 | 40.18 | **40.73** |
| Mistral-7B-Instruct-v0.2 | 42.71 | 30.06 | 37.37 | 40.71 | 40.47 | **40.90** |
| Qwen2-7B-Instruct | 40.71 | 29.65 | 35.63 | 38.47 | 38.19 | **39.16** |
| InternLM-2.5-7B-Chat-1M | 43.21 | 32.25 | 34.65 | 37.84 | 37.86 | **38.39** |

> ğŸ’¡ **Conclusion**: DynamicKV **consistently outperforms SOTA** under extreme compression (6.9% context ratio).

### Needle-in-a-Haystack (32K context, 64 cache)
| Method | Accuracy |
|--------|----------|
| FullKV | 92% |
| StreamingLLM | 26% |
| PyramidKV | 72% |
| **DynamicKV** | **83%** |

</div>

<div class="lang-zh" style="display:none">

| æ¨¡å‹ | FullKV | StreamingLLM | H2O | SnapKV | PyramidKV | **DynamicKVï¼ˆoursï¼‰** |
|------|--------|--------------|-----|--------|-----------|----------------------|
| Llama-3-8B-Instruct | 41.95 | 34.70 | 37.20 | 40.30 | 40.18 | **40.73** |
| Mistral-7B-Instruct-v0.2 | 42.71 | 30.06 | 37.37 | 40.71 | 40.47 | **40.90** |
| Qwen2-7B-Instruct | 40.71 | 29.65 | 35.63 | 38.47 | 38.19 | **39.16** |
| InternLM-2.5-7B-Chat-1M | 43.21 | 32.25 | 34.65 | 37.84 | 37.86 | **38.39** |

> ğŸ’¡ **ç»“è®º**ï¼šåœ¨æç«¯å‹ç¼©ï¼ˆ6.9% ä¸Šä¸‹æ–‡æ¯”ä¾‹ï¼‰ä¸‹ï¼ŒDynamicKV **å…¨é¢è¶…è¶Šç°æœ‰ SOTA æ–¹æ³•**ã€‚

### Needle-in-a-Haystackï¼ˆ32K ä¸Šä¸‹æ–‡ï¼Œ64 ç¼“å­˜ï¼‰
| æ–¹æ³• | å‡†ç¡®ç‡ |
|------|--------|
| FullKV | 92% |
| StreamingLLM | 26% |
| PyramidKV | 72% |
| **DynamicKV** | **83%** |

</div>

---

## âš¡ Quick Start / ä¸€é”®å¯åŠ¨

<div class="lang-en">

### Install
```bash
git clone https://github.com/DreamMr/DynamicKV.git
cd DynamicKV
pip install transformers>=0.44.1
```

### Run Example
```bash
bash run/longbench/scripts/run_qwen2/run_qwen2_7b_instruct_dynamic_v11_maxpool.sh 
```

### Supported Models
- `meta-llama/Llama-3-8B-Instruct`
- `mistralai/Mistral-7B-Instruct-v0.2`
- `Qwen/Qwen2-7B-Instruct`
- `internlm/internlm2_5-7b-chat-1m`

</div>

<div class="lang-zh" style="display:none">

### å®‰è£…
```bash
git clone https://github.com/DreamMr/DynamicKV.git
cd DynamicKV
pip install -r requirements.txt
```

### è¿è¡Œç¤ºä¾‹
```bash
bash run/longbench/scripts/run_qwen2/run_qwen2_7b_instruct_dynamic_v11_maxpool.sh 
```

### æ”¯æŒæ¨¡å‹
- `meta-llama/Llama-3-8B-Instruct`
- `mistralai/Mistral-7B-Instruct-v0.2`
- `Qwen/Qwen2-7B-Instruct`
- `internlm/internlm2_5-7b-chat-1m`

</div>

---

## ğŸ“š Citation / å¼•ç”¨

<div class="lang-en">

If you find DynamicKV useful, please cite our paper:

```bibtex
@misc{zhou2025dynamickvtaskawareadaptivekv,
      title={DynamicKV: Task-Aware Adaptive KV Cache Compression for Long Context LLMs}, 
      author={Xiabin Zhou and Wenbin Wang and Minyan Zeng and Jiaxian Guo and Xuebo Liu and Li Shen and Min Zhang and Liang Ding},
      year={2025},
      eprint={2412.14838},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2412.14838}, 
}
```

</div>

<div class="lang-zh" style="display:none">

å¦‚æœæ‚¨è§‰å¾— DynamicKV å¯¹æ‚¨çš„ç ”ç©¶æœ‰å¸®åŠ©ï¼Œè¯·å¼•ç”¨æˆ‘ä»¬çš„è®ºæ–‡ï¼š

```bibtex
@misc{zhou2025dynamickvtaskawareadaptivekv,
      title={DynamicKV: Task-Aware Adaptive KV Cache Compression for Long Context LLMs}, 
      author={Xiabin Zhou and Wenbin Wang and Minyan Zeng and Jiaxian Guo and Xuebo Liu and Li Shen and Min Zhang and Liang Ding},
      year={2025},
      eprint={2412.14838},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2412.14838}, 
}
```

</div>


> ğŸ”— **Code**: [https://github.com/DreamMr/DynamicKV](https://github.com/DreamMr/DynamicKV)  
> ğŸ“„ **Paper**: [arXiv:2412.14838](https://arxiv.org/abs/2412.14838)


âœ… **ä½¿ç”¨è¯´æ˜**ï¼š
- æ­¤ README åœ¨ GitHub ä¸Šé»˜è®¤æ˜¾ç¤ºè‹±æ–‡ï¼Œç‚¹å‡»â€œä¸­æ–‡â€æŒ‰é’®å¯åˆ‡æ¢ä¸ºä¸­æ–‡ï¼ˆä¾èµ–æµè§ˆå™¨ JavaScriptï¼‰ã€‚
- è‹¥éœ€çº¯é™æ€ç‰ˆæœ¬ï¼ˆæ—  JSï¼‰ï¼Œä¹Ÿå¯æä¾›åŒè¯­å¹¶åˆ—ç‰ˆï¼Œæ¬¢è¿å‘ŠçŸ¥ã€‚